{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 76G\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 6.8G Feb  3 14:23 all_object_data_in_dictionary_format.pkl\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 429M Feb 12 12:33 autoscan_features.2.csv\n",
      "-rw-rw-r--. 1 pughdr g-pughdr  13G Feb  3 14:38 normalized_image_object_data_in_numpy_format.pkl\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:32 stamps_0.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:30 stamps_1.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:31 stamps_2.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:30 stamps_3.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:34 stamps_4.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:31 stamps_5.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:31 stamps_6.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 16:38 stamps_7.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:30 stamps_8.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.5G Feb  7 16:16 stamps_9.tar\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/all_object_data_in_dictionary_format.pkl\", \"rb\") as pickled_data:\n",
    "    all_data = pickle.load(pickled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = all_data[\"images\"], all_data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pughdr/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "Z = scaler.fit_transform(X.reshape(-1, 3 * 51**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = model_selection.train_test_split(Z, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715526, 7803)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178882, 7803)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with a simple DNN\n",
    "\n",
    "Start with a simple Deep Neural Network (DNN) with a single hidden layer as a benchmark. A simple DNN is able to achieve over 90% accuracy and recall on the test set! Unlike classical ML approaches which require expensive to obtain hand-engineered features, this simple DNN works with the raw image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = keras.models.Sequential([\n",
    "    keras.layers.Flatten(data_format=\"channels_first\", input_shape=(3, 51, 51)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Recall()\n",
    "]\n",
    "model_fn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=_metrics)\n",
    "model_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "715526/715526 [==============================] - 192s 269us/sample - loss: 0.1993 - binary_accuracy: 0.9228 - recall_2: 0.9275\n",
      "Epoch 2/2\n",
      "715526/715526 [==============================] - 182s 254us/sample - loss: 0.1669 - binary_accuracy: 0.9358 - recall_2: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2824254710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.fit(training_features.reshape((-1, 3, 51, 51)), training_target, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178882/178882 [==============================] - 36s 199us/sample - loss: 0.1834 - binary_accuracy: 0.9294 - recall_2: 0.8952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1834107443779334, 0.9293613, 0.89524364]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.evaluate(testing_features.reshape((-1, 3, 51, 51)), testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve upon DNN by adding convolutions\n",
    "\n",
    "Show how we can improve performance by adding convolutional layers to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 16, 49, 49)        448       \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 16, 49, 49)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 16, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 22, 22)        4640      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 32, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 32, 11, 11)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 9, 9)          18496     \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 64, 9, 9)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 64, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 154,913\n",
      "Trainable params: 154,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fn = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), data_format=\"channels_first\", input_shape=(3, 51, 51)),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Flatten(data_format=\"channels_first\"),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Recall(),\n",
    "]\n",
    "model_fn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=_metrics)\n",
    "model_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "715526/715526 [==============================] - 268s 375us/sample - loss: 0.1297 - binary_accuracy: 0.9529 - recall_11: 0.9592\n",
      "Epoch 2/10\n",
      "715526/715526 [==============================] - 252s 353us/sample - loss: 0.1044 - binary_accuracy: 0.9634 - recall_11: 0.9694\n",
      "Epoch 3/10\n",
      "715526/715526 [==============================] - 250s 349us/sample - loss: 0.0986 - binary_accuracy: 0.9654 - recall_11: 0.9714\n",
      "Epoch 4/10\n",
      "715526/715526 [==============================] - 249s 348us/sample - loss: 0.0943 - binary_accuracy: 0.9671 - recall_11: 0.9726\n",
      "Epoch 5/10\n",
      "715526/715526 [==============================] - 248s 346us/sample - loss: 0.0917 - binary_accuracy: 0.9682 - recall_11: 0.9738\n",
      "Epoch 6/10\n",
      "715526/715526 [==============================] - 247s 345us/sample - loss: 0.0899 - binary_accuracy: 0.9689 - recall_11: 0.9744\n",
      "Epoch 7/10\n",
      "715526/715526 [==============================] - 247s 345us/sample - loss: 0.0882 - binary_accuracy: 0.9694 - recall_11: 0.9747\n",
      "Epoch 8/10\n",
      "715526/715526 [==============================] - 246s 343us/sample - loss: 0.0869 - binary_accuracy: 0.9699 - recall_11: 0.9752\n",
      "Epoch 9/10\n",
      "715526/715526 [==============================] - 246s 344us/sample - loss: 0.0862 - binary_accuracy: 0.9702 - recall_11: 0.9755\n",
      "Epoch 10/10\n",
      "715526/715526 [==============================] - 244s 341us/sample - loss: 0.0851 - binary_accuracy: 0.9706 - recall_11: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09701eeb00>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.fit(training_features.reshape((-1, 3, 51, 51)), training_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178882/178882 [==============================] - 27s 153us/sample - loss: 0.0966 - binary_accuracy: 0.9677 - recall_11: 0.9657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09656245221981352, 0.96772176, 0.96567065]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.evaluate(testing_features.reshape((-1, 3, 51, 51)), testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve speed of convergence by adding batch normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 16, 49, 49)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16, 49, 49)        196       \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 16, 49, 49)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 16, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 22, 22)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 32, 22, 22)        88        \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 32, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 32, 11, 11)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 64, 9, 9)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 64, 9, 9)          36        \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 64, 9, 9)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 64, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 155,745\n",
      "Trainable params: 155,329\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fn = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), data_format=\"channels_first\", input_shape=(3, 51, 51)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Flatten(data_format=\"channels_first\"),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Recall(),\n",
    "]\n",
    "model_fn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=_metrics)\n",
    "model_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "715526/715526 [==============================] - 371s 519us/sample - loss: 0.1370 - binary_accuracy: 0.9500 - recall_10: 0.9561\n",
      "Epoch 2/10\n",
      "715526/715526 [==============================] - 350s 490us/sample - loss: 0.1104 - binary_accuracy: 0.9610 - recall_10: 0.9672\n",
      "Epoch 3/10\n",
      "715526/715526 [==============================] - 346s 483us/sample - loss: 0.1012 - binary_accuracy: 0.9646 - recall_10: 0.9704\n",
      "Epoch 4/10\n",
      "715526/715526 [==============================] - 345s 482us/sample - loss: 0.0955 - binary_accuracy: 0.9666 - recall_10: 0.9721\n",
      "Epoch 5/10\n",
      "715526/715526 [==============================] - 349s 487us/sample - loss: 0.0911 - binary_accuracy: 0.9682 - recall_10: 0.9737\n",
      "Epoch 6/10\n",
      "715526/715526 [==============================] - 347s 484us/sample - loss: 0.0877 - binary_accuracy: 0.9696 - recall_10: 0.9748\n",
      "Epoch 7/10\n",
      "715526/715526 [==============================] - 349s 487us/sample - loss: 0.0849 - binary_accuracy: 0.9705 - recall_10: 0.9757\n",
      "Epoch 8/10\n",
      "715526/715526 [==============================] - 349s 487us/sample - loss: 0.0826 - binary_accuracy: 0.9713 - recall_10: 0.9761\n",
      "Epoch 9/10\n",
      "715526/715526 [==============================] - 350s 490us/sample - loss: 0.0799 - binary_accuracy: 0.9721 - recall_10: 0.9770\n",
      "Epoch 10/10\n",
      "715526/715526 [==============================] - 348s 487us/sample - loss: 0.0778 - binary_accuracy: 0.9728 - recall_10: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09a854a7b8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.fit(training_features.reshape((-1, 3, 51, 51)), training_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178882/178882 [==============================] - 29s 164us/sample - loss: 0.0890 - binary_accuracy: 0.9697 - recall_10: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08902497166420971, 0.96967274, 0.976395]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.evaluate(testing_features.reshape((-1, 3, 51, 51)), testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator API\n",
    "\n",
    "Show how we generate an `EstimatorSpec` from our Keras model. Useful starting point for distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../models/cnn/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f280c1a6780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = (keras.estimator\n",
    "                  .model_to_estimator(model_fn, model_dir=\"../models/cnn/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_fn = (tf.estimator\n",
    "                       .inputs\n",
    "                       .numpy_input_fn(x=training_features.reshape((-1, 3, 51, 51)),\n",
    "                                       y=training_target.reshape((-1, 1)),\n",
    "                                       batch_size=128,\n",
    "                                       num_epochs=5,\n",
    "                                       shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='../models/cnn/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('../models/cnn/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_15/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_15/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_16/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_16/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_17/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_17/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_13/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_13/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_14/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_14/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_18; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_19; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_20; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_21; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_22; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_23; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_24; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_25; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_26; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_27; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_28; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_29; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/cnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../models/cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.057146102, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 44.7136\n",
      "INFO:tensorflow:loss = 0.09083557, step = 1100 (2.237 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e787c295d2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=training_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /home/pughdr/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-21T13:33:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/cnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-21-13:34:00\n",
      "INFO:tensorflow:Saving dict for global step 1000: binary_accuracy = 0.96870005, global_step = 1000, loss = 0.0922576, recall_4 = 0.9762923\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../models/cnn/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "evaluation_input_fn = (tf.estimator\n",
    "                         .inputs.numpy_input_fn(x=testing_features.reshape((-1, 3, 51, 51)),\n",
    "                                                y=testing_target.reshape((-1, 1)),\n",
    "                                                num_epochs=1,\n",
    "                                                shuffle=False))\n",
    "\n",
    "evaluation_results = estimator.evaluate(input_fn=evaluation_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': 0.96870005,\n",
       " 'loss': 0.0922576,\n",
       " 'recall_4': 0.9762923,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features: tf.Tensor, labels: tf.Tensor, mode: tf.estimator.ModeKeys) -> tf.estimator.EstimatorSpec:\n",
    "    \"\"\"Function builds a DAG and wraps it in an EstimatorSpec\"\"\"\n",
    "    \n",
    "    # reshape the inputs\n",
    "    input_layer = tf.reshape(features, [-1, 3, 51, 51])\n",
    "    \n",
    "    # convolutional layers\n",
    "    convolution_layer_1 = tf.layers.conv2d(inputs=input_layer,\n",
    "                                           filters=32,\n",
    "                                           kernel_size=(5, 5),\n",
    "                                           padding=\"same\",\n",
    "                                           data_format=\"channels_first\",\n",
    "                                           activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_layer_1 = tf.layers.max_pooling2d(inputs=convolution_layer_1,\n",
    "                                              pool_size=(2, 2),\n",
    "                                              strides=2,\n",
    "                                              data_format=\"channels_first\",)\n",
    "    \n",
    "    convolution_layer_2 = tf.layers.conv2d(inputs=pooling_layer_1,\n",
    "                                           filters=64,\n",
    "                                           kernel_size=(5, 5),\n",
    "                                           padding=\"same\",\n",
    "                                           data_format=\"channels_first\",\n",
    "                                           activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_layer_2 = tf.layers.max_pooling2d(inputs=convolution_layer_2,\n",
    "                                              pool_size=(2, 2),\n",
    "                                              strides=2,\n",
    "                                              data_format=\"channels_first\",)\n",
    "    \n",
    "    # dense layers\n",
    "    flatten_layer = tf.layers.flatten(inputs=pooling_layer_2)\n",
    "    dense_layer = tf.layers.dense(inputs=flatten_layer,\n",
    "                                  units=1024,\n",
    "                                  activation=tf.nn.relu)\n",
    "    dropout_layer = tf.layers.dropout(inputs=dense_layer,\n",
    "                                      rate=0.45,\n",
    "                                      training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # output and loss layers\n",
    "    logit_layer = tf.layers.dense(inputs=dropout_layer, units=1)\n",
    "    predicted_labels = tf.argmax(inputs=logit_layer)\n",
    "    loss = tf.losses.softmax_cross_entropy(labels=labels, logits=logit_layer)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, predicted_labels)\n",
    "        recall = tf.metrics.recall(labels, predicted_labels)\n",
    "        f_score = tf.metrics.f_score(labels, predicted_labels)\n",
    "        auc = tf.metrics.accuracy(labels, predicted_labels)\n",
    "        eval_metric_ops = {\"accuracy\": accuracy,\n",
    "                           \"recall\": recall,\n",
    "                           \"area_under_curve\": auc,\n",
    "                           \"f_score\": f_score}\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    else:\n",
    "        predictions = {\"classes\": predicted_labels,\n",
    "                       \"probabilities\": tf.nn.sigmoid(logit_layer)}\n",
    "        estimator_spec = tf.estimatorim.EstimatorSpec(mode, predictions)\n",
    "    \n",
    "    return estimator_spec\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_nova_estimator = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                              model_dir=\"../models/super-nova-classifiers/cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.inputs.numpy_input_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_fn = tf.estimator.inputs.numpy_input_fn(x=training_features,\n",
    "                                                       y=training_labels,\n",
    "                                                       batch_size=128,\n",
    "                                                       num_epochs=None,\n",
    "                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_nova_estimator.train(input_fn=training_input_fn, steps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_input_fn = tf.estimator.inputs.numpy_input_fn(x=testing_features,\n",
    "                                                         y=testing_labels,\n",
    "                                                         num_epochs=1,\n",
    "                                                         shuffle=False)\n",
    "\n",
    "evaluation_results = super_nova_estimator.evaluate(input_fn=evaluation_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
