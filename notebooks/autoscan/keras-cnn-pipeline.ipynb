{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 76G\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 6.8G Feb  3 14:23 all_object_data_in_dictionary_format.pkl\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 429M Feb 12 12:33 autoscan_features.2.csv\n",
      "-rw-rw-r--. 1 pughdr g-pughdr  13G Feb  3 14:38 normalized_image_object_data_in_numpy_format.pkl\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:32 stamps_0.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:30 stamps_1.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:31 stamps_2.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:30 stamps_3.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:34 stamps_4.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:31 stamps_5.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:31 stamps_6.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 16:38 stamps_7.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.6G Feb  7 15:30 stamps_8.tar\n",
      "-rw-rw-r--. 1 pughdr g-pughdr 5.5G Feb  7 16:16 stamps_9.tar\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/all_object_data_in_dictionary_format.pkl\", \"rb\") as pickled_data:\n",
    "    all_data = pickle.load(pickled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = all_data[\"images\"], all_data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pughdr/.conda/envs/tensorflow-gpu-tutorials/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "Z = scaler.fit_transform(X.reshape(-1, 3 * 51**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = model_selection.train_test_split(Z, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715526, 7803)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178882, 7803)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with a simple DNN\n",
    "\n",
    "Start with a simple Deep Neural Network (DNN) with a single hidden layer as a benchmark. A simple DNN is able to achieve over 90% accuracy and recall on the test set! Unlike classical ML approaches which require expensive to obtain hand-engineered features, this simple DNN works with the raw image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = keras.models.Sequential([\n",
    "    keras.layers.Flatten(data_format=\"channels_first\", input_shape=(3, 51, 51)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Recall()\n",
    "]\n",
    "model_fn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=_metrics)\n",
    "model_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "715526/715526 [==============================] - 192s 269us/sample - loss: 0.1993 - binary_accuracy: 0.9228 - recall_2: 0.9275\n",
      "Epoch 2/2\n",
      "715526/715526 [==============================] - 182s 254us/sample - loss: 0.1669 - binary_accuracy: 0.9358 - recall_2: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2824254710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.fit(training_features.reshape((-1, 3, 51, 51)), training_target, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178882/178882 [==============================] - 36s 199us/sample - loss: 0.1834 - binary_accuracy: 0.9294 - recall_2: 0.8952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1834107443779334, 0.9293613, 0.89524364]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.evaluate(testing_features.reshape((-1, 3, 51, 51)), testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve upon DNN by adding convolutions\n",
    "\n",
    "Show how we can improve performance by adding convolutional layers to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 16, 49, 49)        448       \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 16, 49, 49)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 16, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 22, 22)        4640      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 32, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 32, 11, 11)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 9, 9)          18496     \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 64, 9, 9)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 64, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 154,913\n",
      "Trainable params: 154,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fn = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), data_format=\"channels_first\", input_shape=(3, 51, 51)),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Flatten(data_format=\"channels_first\"),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Recall(),\n",
    "]\n",
    "model_fn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=_metrics)\n",
    "model_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "715526/715526 [==============================] - 268s 375us/sample - loss: 0.1297 - binary_accuracy: 0.9529 - recall_11: 0.9592\n",
      "Epoch 2/10\n",
      "715526/715526 [==============================] - 252s 353us/sample - loss: 0.1044 - binary_accuracy: 0.9634 - recall_11: 0.9694\n",
      "Epoch 3/10\n",
      "715526/715526 [==============================] - 250s 349us/sample - loss: 0.0986 - binary_accuracy: 0.9654 - recall_11: 0.9714\n",
      "Epoch 4/10\n",
      "715526/715526 [==============================] - 249s 348us/sample - loss: 0.0943 - binary_accuracy: 0.9671 - recall_11: 0.9726\n",
      "Epoch 5/10\n",
      "715526/715526 [==============================] - 248s 346us/sample - loss: 0.0917 - binary_accuracy: 0.9682 - recall_11: 0.9738\n",
      "Epoch 6/10\n",
      "715526/715526 [==============================] - 247s 345us/sample - loss: 0.0899 - binary_accuracy: 0.9689 - recall_11: 0.9744\n",
      "Epoch 7/10\n",
      "715526/715526 [==============================] - 247s 345us/sample - loss: 0.0882 - binary_accuracy: 0.9694 - recall_11: 0.9747\n",
      "Epoch 8/10\n",
      "715526/715526 [==============================] - 246s 343us/sample - loss: 0.0869 - binary_accuracy: 0.9699 - recall_11: 0.9752\n",
      "Epoch 9/10\n",
      "715526/715526 [==============================] - 246s 344us/sample - loss: 0.0862 - binary_accuracy: 0.9702 - recall_11: 0.9755\n",
      "Epoch 10/10\n",
      "715526/715526 [==============================] - 244s 341us/sample - loss: 0.0851 - binary_accuracy: 0.9706 - recall_11: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09701eeb00>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.fit(training_features.reshape((-1, 3, 51, 51)), training_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178882/178882 [==============================] - 27s 153us/sample - loss: 0.0966 - binary_accuracy: 0.9677 - recall_11: 0.9657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09656245221981352, 0.96772176, 0.96567065]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.evaluate(testing_features.reshape((-1, 3, 51, 51)), testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve speed of convergence by adding batch normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 16, 49, 49)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16, 49, 49)        196       \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 16, 49, 49)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 16, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 22, 22)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 32, 22, 22)        88        \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 32, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 32, 11, 11)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 64, 9, 9)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 64, 9, 9)          36        \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 64, 9, 9)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 64, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 155,745\n",
      "Trainable params: 155,329\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fn = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), data_format=\"channels_first\", input_shape=(3, 51, 51)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), data_format=\"channels_first\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), data_format=\"channels_first\"),\n",
    "    keras.layers.Flatten(data_format=\"channels_first\"),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(),\n",
    "    keras.metrics.Recall(),\n",
    "]\n",
    "model_fn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=_metrics)\n",
    "model_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "715526/715526 [==============================] - 371s 519us/sample - loss: 0.1370 - binary_accuracy: 0.9500 - recall_10: 0.9561\n",
      "Epoch 2/10\n",
      "715526/715526 [==============================] - 350s 490us/sample - loss: 0.1104 - binary_accuracy: 0.9610 - recall_10: 0.9672\n",
      "Epoch 3/10\n",
      "715526/715526 [==============================] - 346s 483us/sample - loss: 0.1012 - binary_accuracy: 0.9646 - recall_10: 0.9704\n",
      "Epoch 4/10\n",
      "715526/715526 [==============================] - 345s 482us/sample - loss: 0.0955 - binary_accuracy: 0.9666 - recall_10: 0.9721\n",
      "Epoch 5/10\n",
      "715526/715526 [==============================] - 349s 487us/sample - loss: 0.0911 - binary_accuracy: 0.9682 - recall_10: 0.9737\n",
      "Epoch 6/10\n",
      "715526/715526 [==============================] - 347s 484us/sample - loss: 0.0877 - binary_accuracy: 0.9696 - recall_10: 0.9748\n",
      "Epoch 7/10\n",
      "715526/715526 [==============================] - 349s 487us/sample - loss: 0.0849 - binary_accuracy: 0.9705 - recall_10: 0.9757\n",
      "Epoch 8/10\n",
      "715526/715526 [==============================] - 349s 487us/sample - loss: 0.0826 - binary_accuracy: 0.9713 - recall_10: 0.9761\n",
      "Epoch 9/10\n",
      "715526/715526 [==============================] - 350s 490us/sample - loss: 0.0799 - binary_accuracy: 0.9721 - recall_10: 0.9770\n",
      "Epoch 10/10\n",
      "715526/715526 [==============================] - 348s 487us/sample - loss: 0.0778 - binary_accuracy: 0.9728 - recall_10: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09a854a7b8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.fit(training_features.reshape((-1, 3, 51, 51)), training_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178882/178882 [==============================] - 29s 164us/sample - loss: 0.0890 - binary_accuracy: 0.9697 - recall_10: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08902497166420971, 0.96967274, 0.976395]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn.evaluate(testing_features.reshape((-1, 3, 51, 51)), testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
