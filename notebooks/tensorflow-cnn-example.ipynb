{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/all_object_data_in_dictionary_format.pkl\", \"rb\") as pickled_data:\n",
    "    all_data = pickle.load(pickled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = all_data[\"images\"], all_data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "Z = scaler.fit_transform(X.reshape(-1, 3 * 51**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_features, training_target), (testing_features, testing_target) = model_selection.train_test_split(Z, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.Estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features: tf.Tensor, labels: tf.Tensor, mode: tf.estimator.ModeKeys) -> tf.estimator.EstimatorSpec:\n",
    "    \"\"\"Function builds a DAG and wraps it in an EstimatorSpec\"\"\"\n",
    "    \n",
    "    # reshape the inputs\n",
    "    input_layer = tf.reshape(features, [-1, 3, 51, 51])\n",
    "    \n",
    "    # convolutional layers\n",
    "    convolution_layer_1 = tf.layers.conv2d(inputs=input_layer,\n",
    "                                           filters=32,\n",
    "                                           kernel_size=(5, 5),\n",
    "                                           padding=\"same\",\n",
    "                                           data_format=\"channels_first\",\n",
    "                                           activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_layer_1 = tf.layers.max_pooling2d(inputs=convolution_layer_1,\n",
    "                                              pool_size=(2, 2),\n",
    "                                              strides=2,\n",
    "                                              data_format=\"channels_first\",)\n",
    "    \n",
    "    convolution_layer_2 = tf.layers.conv2d(inputs=input_layer,\n",
    "                                           filters=64,\n",
    "                                           kernel_size=(5, 5),\n",
    "                                           padding=\"same\",\n",
    "                                           data_format=\"channels_first\",\n",
    "                                           activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_layer_2 = tf.layers.max_pooling2d(inputs=convolution_layer_2,\n",
    "                                              pool_size=(2, 2),\n",
    "                                              strides=2,\n",
    "                                              data_format=\"channels_first\",)\n",
    "    \n",
    "    # dense layers\n",
    "    flatten_layer = tf.layers.flatten(inputs=pooling_layer_2)\n",
    "    dense_layer = tf.layers.dense(inputs=flatten_layer,\n",
    "                                  units=1024,\n",
    "                                  activation=tf.nn.relu)\n",
    "    dropout_layer = tf.layers.dropout(inputs=dense_layer,\n",
    "                                      rate=0.45,\n",
    "                                      training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    # output and loss layers\n",
    "    logit_layer = tf.layers.dense(inputs=dropout_layer, units=1)\n",
    "    predicted_labels = tf.argmax(inputs=logit_layer)\n",
    "    loss = tf.losses.softmax_cross_entropy(labels=labels, logits=logit_layer)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss,\n",
    "                                      global_step=tf.train.get_global_step())\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, predicted_labels)\n",
    "        recall = tf.metrics.recall(labels, predicted_labels)\n",
    "        f_score = tf.metrics.f_score(labels, predicted_labels)\n",
    "        auc = tf.metrics.accuracy(labels, predicted_labels)\n",
    "        eval_metric_ops = {\"accuracy\": accuracy,\n",
    "                           \"recall\": recall,\n",
    "                           \"area_under_curve\": auc,\n",
    "                           \"f_score\": f_score}\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    else:\n",
    "        predictions = {\"classes\": predicted_labels,\n",
    "                       \"probabilities\": tf.nn.sigmoid(logit_layer)}\n",
    "        estimator_spec = tf.estimatorim.EstimatorSpec(mode, predictions)\n",
    "    \n",
    "    return estimator_spec\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_nova_estimator = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                              model_dir=\"../models/super-nova-classifiers/cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.inputs.numpy_input_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_fn = tf.estimator.inputs.numpy_input_fn(x=training_features,\n",
    "                                                       y=training_labels,\n",
    "                                                       batch_size=128,\n",
    "                                                       num_epochs=None,\n",
    "                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_nova_estimator.train(input_fn=training_input_fn, steps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_input_fn = tf.estimator.inputs.numpy_input_fn(x=testing_features,\n",
    "                                                         y=testing_labels,\n",
    "                                                         num_epochs=1,\n",
    "                                                         shuffle=False)\n",
    "\n",
    "evaluation_results = super_nova_estimator.evaluate(input_fn=evaluation_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
